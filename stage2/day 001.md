# 游戏引擎架构

## 并行与并发的定义

### 并发

​	软件的并发部分利用多个控制流来解决同一个问题。这些控制流可以实现为运行在单个进程上下文中的多个线程，也可以实现为运行在一台或多台计算机上的多个协作进程。还可以使用其他技术(如Fibers或协程)在进程中实现多个控制流。

​	并发编程与顺序编程的主要区别在于**读取和/或写入共享数据**。并发编程的核心问题是如何协调共享数据文件的多个读取器和多个写入器，以确保可预测的、正确的结果。并发问题的关键是识别和消除数据竞争。

### 并行

​	并行计算机可以同时执行多个任务，串行计算机一次只能做一件事。

#### 隐式和显式并行

​	通过思考在给定的设计中并行解决了什么问题？我们可以将并行性大致分为两类：隐式和显式。

​	隐式并行是指在CPU内使用并行组件，以提高**单个指令流**的性能。这也被称为指令级并行(ILP)，因为CPU从单个线程执行指令，但每条指令的执行都具有一定程度的并行性。流水线架构就是典型的隐式并行。GPU也广泛应用隐式并行。

​	显式并行是在计算机中使用重复的硬件组件，以**同时运行多个指令**。多核、超线程、集群都是显式并行的例子。

### 任务并行与数据并行

​	还可以根据并行完成的工作类型将其分为两大类：

- 任务并行：多个异构操作并行执行。比如在一个核心上执行动画计算，同时在另一个核心上执行碰撞检测。
- 数据并行：单指令，多数据。比如在多个核心上同时做100个浮点乘法。

​	大多数并发程序都不同程度地利用了任务和数据的并行。

### Flynn 分类法

- 单指令单数据（SISD）：操作于单个数据流的单个指令流。
- 多指令多数据（MIMD）：操作在多个独立数据流上的多个指令流。
- 单指令多数据（SIMD）：操作于多个数据流的单个指令流。
- 多指令单数据（MISD）：多个指令流都操作在单个数据流上。（在游戏中很少使用）

#### 单数据流与多数据流

​	**“数据流”不是指数组。**比如进行二元运算时，单数据流指的是单个“输入对”，单个输出。

​	多指令流一般对应多个核心。也可以时单个核心进行分时。

​	**GPU并行：单指令多线程（SIMT）。**

​	**并发程序不需要并行硬件，并行硬件也不仅仅用于运行并发程序。**

## 隐式并行

​	常见的使用隐式并行的方法有：流水线、超标量设计、超长指令字。

### 流水线

​	CPU执行一条机器指令时，必须经过许多不同的阶段。每个CPU都有不同的颗粒度划分，都会实现以下几个基本阶段：

- *取指*：要执行的指令是从指令指针寄存器(IP)所指向的内存位置读取的。
- *解码*：指令字被分解为它的操作码、寻址模式和操作数。
- *执行*：根据操作码，在CPU中选择合适的功能单元(ALU, FPU，内存控制器等)。该指令连同任何相关的操作数数据被分派到所选的组件进行处理。
- *内存寻址*：如果指令涉及读或写内存，内存控制器在此阶段执行相应的操作。
- *写回寄存器*：执行指令的功能单元(ALU, FPU等)将其结果写回目标寄存器。

​	指令执行的每个阶段实际上是由CPU内的不同硬件处理的。控制单元(CU)和内存控制器处理指令获取阶段。CU内部的另一个电路处理解码阶段。ALU, FPU或VPU处理大部分的执行阶段。内存控制器处理内存寻址阶段。“写回”阶段主要涉及寄存器。

​	在开始执行下一个指令之前，我们不是等待每条指令完成所有五个阶段，而是在每个时钟周期开始执行一条新指令。如下图所示：

<img src="C:\Users\Clan\OneDrive\桌面\study\研二\day by day\pictures\image-20220917105658461.png" alt="image-20220917105658461" style="zoom: 80%;" />

​	流水线是并行的一种形式，称为指令级并行(ILP)。ILP通常对程序员透明。通过调整代码和数据的设计，最大限度地利用流水线。

# 基于物理的建模与动画

## 天文模拟

### 聚簇

​	虽然万有引力关于两个物体间距离的平方衰减，但由于大量距离很远的粒子仍能够在很大的距离内产生强大的引力。所以，应该**将远距离的粒子聚成一个簇**来节省计算时间。

​	已知粒子$i$，$j$，分别位于$\mathbf{x}_i$，$\mathbf{x}_j$，它们两的距离相对于到粒子$\mathbf{x}$的距离而言很近。定义$R_i$、$R_j$为粒子$i$、$j$与$\mathbf{x}$的距离，并且令$\hat{\mathbf{u}}_i$、$\hat{\mathbf{u}}_j$为以$\mathbf{x}$为起点的到粒子$i$、$j$的方向向量。那么，粒子$i$、$j$对$\mathbf{x}$产生的净加速度为：
$$
a=G\left[\frac{m_i\hat{\mathbf{u}}_i}{R_i^2}+\frac{m_j\hat{\mathbf{u}}_j}{R_j^2}\right]
$$
![image-20220917133840088](C:\Users\Clan\OneDrive\桌面\study\研二\day by day\pictures\image-20220917133840088.png)

​	 尝试将粒子$i$，$j$聚集成一个簇，质量为$M=m_i+m_j$，质心定义为粒子位置关于质量的加权平均，即：
$$
\mathbf{x}_c=\frac{m_i\mathbf{x}_i+m_j\mathbf{x}_j}{M}
$$
​	现在令$r_i$、$r_j$为粒子$i$、$j$到质心的距离，令$R$为$\mathbf{x}$到质心的距离，令$\hat{\mathbf{u}}$为指向质心的方向向量。如图所示，我们创造了一个质量为M、位置为$\mathbf{x}_c$的虚拟粒子，该粒子对$\mathbf{x}$产生的加速度为：
$$
a^c=G\frac{M\hat{\mathbf{u}}}{R^2}
$$
​	显然$\hat{\mathbf{u}}=\frac{\mathbf{x}_c-\mathbf{x}}{R}$，再将$M$和$\mathbf{x}_c$展开带入上式可得：
$$
a^c=G\left[\frac{m_i(\mathbf{x}_i-\mathbf{x})/R}{R^2}+\frac{m_j(\mathbf{x}_j-\mathbf{x})/R}{R^2}\right]
$$
​	将$R$替换为$\frac{R}{R_i}R_i$和$\frac{R}{R_j}R_j$，并且记$\hat{\mathbf{u}}_i=\frac{(\mathbf{x}_i-\mathbf{x})}{R_i}$，$\hat{\mathbf{u}}_j=\frac{(\mathbf{x}_j-\mathbf{x})}{R_j}$，则上式可以转写为：
$$
a^c=G
\left[
\left(\frac{R_i}{R}\right)^3\frac{m_i\hat{\mathbf{u}}_i}{R_i^2}+
\left(\frac{R_j}{R}\right)^3\frac{m_j\hat{\mathbf{u}}_j}{R_j^2}
\right]
$$
​	此式表示估算的加速度，与精确加速度相比，只有标量因子$\left(\frac{R_i}{R}\right)^3$、$\left(\frac{R_j}{R}\right)^3$不同。可以将这两个标量因子看作$1.0$加上一个由$\frac{r_i}{R}$、$\frac{r_j}{R}$控制的偏移量。因此，**如果$\frac{r_i}{R}$和$\frac{r_j}{R}$的值都很小，那么误差就会很小。故只要确保粒子到簇的距离远大于聚簇粒子包围球的半径，便可最小化加速度的误差。**

​	综上，假设将封闭区域中一些粒子表示为其质心处的单个大粒子，那么这个大粒子对某个远距离粒子产生的加速度，与原本分散的粒子群相比，几乎有着相同的效果。这种近似方法产生的误差由$\frac{r}{R}$决定，其中$r$是簇中粒子到质心的最大距离，$R$是受影响粒子到质心的距离。

### 采用均匀网格的简单算法

<img src="C:\Users\Clan\OneDrive\桌面\study\研二\day by day\pictures\image-20220917143656098.png" alt="image-20220917143656098"  />

​	构造一个由体素组成的三维均匀空间网格，每个粒子放置在其哈希对应的体素的粒子成员列表中，然后计算每个体素的质心和总质量。如果总质量为0，质心则在体素中心。

​	任一粒子初始的加速度设置为与该粒子直接相邻的27个体素中所有粒子产生的加速度之和。然后遍历所有非邻接体素，根据体素中虚拟粒子的总质量和位置计算出加速度增量。

​	令粒子数为$N$，体素数为$M$，假设粒子在空间中均匀分布，则每个体素中的平均粒子数为$N/M$。每个粒子的加速度计算次数为$T=(27N/M)+(M-27)$。由于计算次数随体素的数量而变化，因此需要选择最优的$M$，其导数为$\frac{dT}{dM}=\frac{M^2-27N}{M^2}$，解得当$M=\sqrt{27N}$时函数最优。此时$T=2\sqrt{27N}-27$，总体复杂度为$O(N\sqrt{N})$。

​	如果体素数量为完全立方数，则可以令每个轴的划分次数为$D=\lfloor\sqrt[6]{27N}\rfloor$。

### 采用八叉树的自适应算法

![image-20220917145503783](C:\Users\Clan\OneDrive\桌面\study\研二\day by day\pictures\image-20220917145503783.png)

​	**如果保持聚簇大小和距离的比率为常数，则能够在增加聚簇大小的同时，不引起精度下降。**

​	首先构造一个包含所有粒子的包围体，用它来构造一个覆盖所有粒子的八叉树。可以通过指定叶子节点内存放粒子的最大数量$n_{max}$来确定八叉树的深度。当这棵树构建完成后，需要在每个节点中确定一个虚拟粒子，作用于该节点远处的一个粒子上。对于叶子节点$k$，总质量为：$M_k=\sum_{\mathbf{x}_i\in{k}}m_i$，质心为：$\mathbf{c}_k=\frac{\sum_{\mathbf{x}_i\in{k}}m_i\mathbf{x}_i}{M_k}$。对于非叶子节点$p$，总质量为：$M_p=\sum_{i=0}^7{M_i}$，质心为：$\mathbf{c}_p=\frac{\sum_{i=0}^7{M_i}\mathbf{x}_i}{M_p}$。任意节点$n$的加速度函数为：$a_n(\mathbf{x})=GM_k\frac{\mathbf{x}-\mathbf{c}_n}{||\mathbf{x}-\mathbf{c}_n||^3}$。

​	对于任一位于$\mathbf{x}_i$的粒子$i$，首先将粒子的加速度初始化为0，再从根节点开始逐层向下，若聚簇大小和距离的比率满足要求，则用对应的虚拟粒子计算加速度。若到叶子节点时比率仍不能满足要求，则计算叶子节点内的所有粒子产生的加速度之和。

​	需要$O(NlogN)$从上至下将粒子放入叶子节点中，需要$O(NlogN)$从下至上计算虚拟粒子。理想情况下计算每个粒子的加速度需要$O(logN)$的时间（每层计算时间为常数），故总的时间复杂度为$O(NlogN)$。

## 群集系统

​	当众多遵循某种相互作用规则的小型“参与者”大量聚集时，产生的一种大型尺度上的群体行为，被称为涌现现象（*emergent phenomenon*）。比如鱼群、鸟群。每个个体都是独立的决策者，受邻近对象的影响。

​	每个时间步长内，为每个对象维护一张邻近对象的列表。对于每个邻近的对象，计算三个加速度：

- 碰撞规避：防止相邻对象发生碰撞
- 速度匹配：保持单个对象与群体运动的一致性
- 集中：保持群体的完整性

# C++ Primer

## 动态内存和智能指针

​	标准库提供了两种智能指针`shared_ptr`和`unique_ptr`， **智能指针负责自动释放所指向的对象**。`shared_ptr`允许多个指针指向同一对象；`unique_ptr`则“独占”所指向的对象。

​	默认初始化的智能指针中保存着一个空指针。最安全的分配和使用动态内存的方法是调用一个名为`make_shared`或`make_unique`的标准库函数。它们都是模板函数，必须显式指定想要创建的对象的类型。类似于顺序容器的`emplace`成员，它们用参数来构造指定类型的对象。

​	当进行拷贝操作时，`shared_ptr`的引用计数递增；当给`shared_ptr`赋予新值或被销毁时，引用计数递减。一旦一个`shared_ptr`的计数器变为0，他就会自动释放自己所管理的对象。由于在最后一个`shared_ptr`销毁前内存都不会释放，**保证`shared_ptr`在无用之后不再保留就非常重要**。比如，`shared_ptr`存放在容器中，随后重排容器，从而不再需要某些元素，但此时并没有删除无用的元素。

​	程序在三种情况下会使用动态内存：

1. 程序不知道自己需要使用多少对象
2. 程序不知道所需对象的准确类型
3. 程序需要在多个对象间共享数据

​	容器类就是出于第一种原因而使用动态内存的典型例子，而**智能指针常用于在多个对象间共享数据**。某些类分配的资源具有与原对象相独立的生存期，即当我们拷贝一个对象时，我们希望**原对象及其拷贝应该引用相同的底层数据**。

> 如果函数的实参数量未知但是全部实参的类型都相同， 我们可以使用`initializer_list`类型的形参，通过迭代器操作这个列表。

# Vulkan编程指南

## 画一个三角形

​	**步骤1：实例和物理设备选择**

​	应用程序是通过`VkInstance`来使用Vulkan API的。通过描述应用程序和将要使用的API扩展来创建实例。然后查询Vulkan支持的硬件，选择其中一个或多个`VkPhysicalDevices`进行操作。可以通过查询设备属性，选择一个合适的设备。

​	**步骤2：逻辑设备和队列族（Queue families）**

​	选择合适的硬件设备之后，需要指定更详细的`VkPhysicalDevices`特性（多视口、64位浮点等）来创建一个逻辑设备`VkDevice`。还需要指定想要使用的队列族。Vulkan将诸如绘制指令、内存操作提交到`VkQueue`中，进行异步执行。队列由队列族分配，每个队列族支持一个特定操作集合。比如，图形，计算和内存传输操作可以使用独立的队列族。队列族可以作为物理设备选择时的一个参考

​	**步骤3：窗口表面（Window Surface）和交换链（Swap Chain）**

​	我们需要创建一个窗口来显示渲染的图像。我们需要两个组件才能完成窗口渲染：窗口表面（`VkSurfaceKHR`）和交换链（`VkSwapChainKHR`）。因为Vulkan本身完全与平台无关，所有这两个组件都属于Vulkan扩展。

​	交换链是渲染目标的集合。它可以保证我们正在渲染的图像和当前屏幕图像是两个不同的图像。每次绘制一帧时，请求交换链提供一张图像，绘制完成后，图像被返回到交换链中，在之后某个时候被呈现到屏幕上。渲染目标的数量和图像显示到屏幕的时机依赖于显示模式。比如双缓冲、三缓冲等。

​	**步骤4：图像视图（Image View）和帧缓冲**

​	从交换链获取图像后，还不能直接在图像上进行绘制，需要将图像先包装进`VkImageView`和`VkFramebuffer`中。一个图像视图可以引用图像的特定部分，一个帧缓冲可以引用图像视图作为颜色、深度或模板目标。我们预先为每个交换链中的图像创建好图像视图和帧缓冲，然后在绘制时选择对应的那个。

​	**步骤5：渲染层（Render Pass）**

​	渲染层描述了渲染操作使用的图像类型，图像的使用方式，图像的内容如何处理。渲染流程只描述了图像的类型，图像绑定是通过`VkFramebuffer`完成的。

​	**步骤6：图形管线**

​	Vulkan的图形管线可以通过`VkPipeline`对象建立。它描述了显卡的可配置状态，以及使用`VkShaderModule`对象指定的可编程状态。`VkShaderModule`对象由着色器字节码创建。驱动程序知道哪些渲染目标被图形管线使用。Vulkan的图形管线配置需要提前完成，如果我们想要更换着色器，则需要重新创建整个图形管线。因此我们需要提前创建出所有我们需要的图形管线。管线中只有很少部分可以动态配置，比如视口大小和清除颜色（clear color）。

​	**步骤7：指令池和指令缓冲**

​	Vulkan的许多操作需要提交到队列才能执行。这些操作首先被记录到一个`VkCommandBuffer`对象中，然后提交到队列。`VkCommandBuffer`对象由一个关联了特定队列族的`VkCommandPool`分配而来。我们可以提前为每个图像建立指令缓冲，绘制时选择对应的缓冲即可。

​	**步骤8：主循环**

​	首先使用`vkAcquireNextImageKHR`函数从交换链获取一张图像。接着使用`vkQueueSubmit`函数提交图像对应的指令缓冲。最后，使用`vkQueuePresentKHR`函数将图像返回给交换链，显示图像到屏幕。

​	提交给队列的操作会被异步执行。我们需要采取同步措施（比如信号量）来确保操作按正确的顺序执行。绘制指令必须在获取图像之后，`vkQueuePresentKHR`函数调用需要在绘制完成后进行。

## 总结

​	对于绘制一个三角形，我们需要：

- 创建一个`VkInstance`
- 选择一个支持Vulkan的图形设备（`VkPhysicalDevice`）
- 为绘制和显示操作创建`VkDevice`和`VkQueue`
- 创建一个窗口，窗口表面和交换链
- 将交换链图像包装进`VkImageView`
- 创建一个渲染层指定渲染目标和使用方式
- 为渲染层创建帧缓冲
- 配置图形管线
- 为每一个交换链中的图像分配指令缓冲
- 从交换链获取图像进行绘制操作，提交图像对应的指令缓冲，返回图像到交换链
