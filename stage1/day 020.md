review: 005 013 016 018 019

# Game Engine Architecture

## Memory Architectures

#### Instruction Cache and Data Cache

​	The *instruction cache* (`I-cache`) is used to preload executable machine code before it runs, while the data cache (D-cache) is used to speed up read and write operations performed by that machine code. when optimizing our code, we must consider both D-cache and I-cache performance.

#### Write Policy

​	How the cache controller handles writes is known as its *write policy*. In simplest case, all writes to the cache are mirrored to main RAM immediately. In a `copy-back` cache design, Data is first written into the cache and the cache line is only written to main RAM under certain circumstances, such as when a cache line needs to be evicted, or when the program explicitly requests a flush to occur.

#### Cache Coherency

​	It’s typical for each core to have its own L1 cache, but multiple cores might share an L2 cache. In the presence of multiple cores, it’s important for the system to maintain cache coherency, which make sure that the data in the caches belonging to multiple cores match one another. All that matters is that **the running program can never know that the contents of the caches are out of sync**.

#### Avoiding Cache Misses

​	The best way to avoid D-cache misses is to organize your data in contiguous blocks that are as small as possible and then access them sequentially.

​	To avoid I-cache misses, to keep your loops as small as possible in terms of code size, and avoid calling functions within your innermost loops.

​	Inlining a small function can be a big performance boost. However, too much inlining bloats the size of the code, which can cause the performance-critical code to no longer fit within the cache.

### Nonuniform Memory Access (NUMA)

​	There are two different memory architectures: uniform memory access (UMA) and nonuniform memory access (NUMA).

​	In a UMA design, the computer contains a single large bank of main RAM which is visible to all CPU cores in the system. In this case, the cores often contend for access to main RAM and any shared caches.

​	In a NUMA design, each core is provided with a relatively small bank of high-speed RAM called a local store. A local store is typically located on the same die as the core itself. Alternatively, certain cores might only be able to see the physical addresses within its local store, and rely on a *direct memory access controller* (DMAC) to transfer data between the local store and main RAM.

#### PlayStation3 NUMA architecture

![image-20220830135122338](C:\Users\Clan\OneDrive\桌面\study\研一\studys\day by day\pictures\image-20220830135122338.png)

​	The physical address spaces of main RAM, video RAM and the SPUs’ local stores are all totally isolated from one another.

# Vulkan

## Validation Layers

​	Unfortunately, the create function `vkCreateDebugUtilsMessengerEXT` is an extension function, we have to look up its address ourselves using `vkGetInstanceProcAddr`.

```c++
auto func = (PFN_vkCreateDebugUtilsMessengerEXT)vkGetInstanceProcAddr(instance, "vkCreateDebugUtilsMessengerEXT");
func(instance, pCreateInfo, pAllocator, pDebugMessenger);
```

​	Since the debug messenger is specific to our Vulkan instance and its layers, it needs to be explicitly specified as first argument.

​	We create debug messenger after instance and destroy it before instance. This leaves us unable to debug any issues in the `vkCreateInstance` and `vkDestroyInstance` calls. To debug instance, it requires you to pass a `DebugMessengerCreateInfo` struct pointer to the `pNext` filed of `VkInstanceCreateInfo`.

## Physical devices and queue families

### Selecting a physical device

​	After initializing the Vulkan library through a `VkInstance` we need to look for and select a graphics card in the system that supports the features we need. The graphics card will be stored in a `VkPhysicalDevice` handle. This object will be implicitly destroyed when the `VkInstance` is destroyed.

​	Listing the graphics cards is very similar to listing extensions. Then we need to evaluate each of them and check if they are suitable for the operations we want to perform.

### Base device suitability checks

​	Basic device properties like the name, type and supported Vulkan version can be queried using `vkGetPhysicalDeviceProperties`. The support for optional features like texture compression, 64 bit floats can be queried using `vkGetPhysicalDeviceFeatures`.

```c++
VkPhysicalDeviceProperties devicePropertyies;
vkGetPhysicalDeviceProperties(physicalDevice, &devicePropertyies);
VkPhysicalDeviceFeatures deviceFeatures;
vkGetPhysicalDeviceFeatures(physicalDevice, &deviceFeatures);
```

### Queue families

​	We need to check which queue families are supported by the device and which one of these supports the commands that we want to use. We’ll add a new function `findQueueFamilies` that looks for all the queue families we need.

​	It's not possible to use a magic value to indicate the nonexistence of a queue family, since any value of `uint32_t` could in theory be a valid queue family index including 0. We should use C++17 `std::optional<uint32_t>` to distinguish between the case of a value existing or not.

​	We could use `vkGetPhysicalDeviceQueueFamilyProperties` to get all QueueFamilys' properties supported by this physical device. QueueFamily's supported commands code for BIT. For now, We just need graphics commands, which means QueueFamily supports `VK_QUEUE_GRAPHICS_BIT`.

## Logical device and queues

​	After selecting a physical device to use we need to set up a logical device to interface with it. We also need to specify which queues to create now that we’ve queried which queue families are available.

### Specifying the queues to be created

​	The creation of a logical device involves specifying a bunch of details in structs again, of which the first one will be `VkDeviceQueueCreateInfo`. This structure describes the number of queues we want for a single queue family. Actually, **you don’t really need more than one queue for a single queue family**.

​	Vulkan lets you assign priorities to queues to influence the scheduling of command buffer execution using floating point numbers between 0.0 and 1.0. This is required even if there is only a single queue.

### Specifying used device features

​	(Why we need this? we've already specified freatures we'll be using when we pick physical device.)

### Creating the logical device

​	It also requires you to specify *device specific extensions*(**device specific extensions are different from instance specific extensions**) and validation layers (ignored). 